{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2\n",
    "\n",
    "## Tuesday May 28, 2019:\n",
    "* created new SURF_2019 branch of FindMyFriends starting at commit 01753b8fc715284fd8e4fa30621ef5e2c78891e3 (March 3, 2016, Version Bump)\n",
    "* read through aaa.R and other files to see how pre-CD-Hit FindMyFriends clustered data\n",
    "* read some methods from [kebab R package](https://www.bioconductor.org/packages/devel/bioc/manuals/kebabs/man/kebabs.pdf) \n",
    "\n",
    "I read through the vignette for the package and learned about the main features of FindMyFriends (FMF). FMF reads .fasta (or .faa) files into a pangenome object, and then the pangenome object is manipulated and clustered to determine the pan and core genomes for the input files. \n",
    "\n",
    "The first step in FMF is to cluster the genomes based on kmer counts. This is done using a technique called guided pairwise comparison, where a tree is constructed and grouped to represent the relationships between the input sequences. To construct the tree, the genes for each genome are concatenated, kmer count profiles are created for each genome, and then genomes are compared based on their overall kmer count profiles (by calculating the normalized inner product of each vector against each other vector, spectrumkernel from kebab). This similarity matrix is then converted to a distance matrix using the euclidean metric between each genome's kmer count profile, and the distance matrix is clustered (using hclust, method = ward.D2) to generate a dendrogram. Subtrees of the dendrogram are then compared and grouped, and each time a subtree is grouped with another subtree, a random sample is chosen to represent the subtree for the next comparison. This tree can then be further analyzed. \n",
    "\n",
    "After reading and learning about FindMyFriends, I installed the package (version 1.1.6) (along with a ton of dependencies!) and tested out the functionality using the examples from the vignette. I used 9 Mycoplasma pneumonia genomes that were provided in the package. \n",
    "\n",
    "I was able to group the genes using guided pairwise comparison (gpc) and classify the genes into core, accessory, or singleton categories: ![geneGrouping](images/w2/geneGrouping.png)\n",
    "I could also get broad statistics about the genomes: ![stats](images/w2/broadStats.png) ![summaryGraphs](images/w2/summaryGraphs.png) ![evo](images/w2/plotEvolution.png)\n",
    "\n",
    "I was also able to generate two different heatmaps for the genomes. The first groups the genomes based on the percentage of shared genes: ![sharedGenesHeatmap](images/w2/percentSharedGenesHeatmap.png)\n",
    "I also generated a heatmap of the genomes using cosine similarity distances of the kmer feature vectors for each genome, and it was very similar to the previous heatmaps with the same genome groupings: ![kmerHeatmap](images/w2/5merSimHeatmap.png)\n",
    "\n",
    "For fun, I also generated a circular phylogenetic tree... ![circularTree](images/w2/circularTree.png)\n",
    "and a panchromosome map that tries to link the genes based on similar neighboring genes: ![panc](images/w2/panchromosome.png) although I'm not too sure what information (if any) I could actually get from this graph. \n",
    "\n",
    "Next, I decided to try to run FindMyFriends for the 26 genomes that were analyzed last week. Code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(FindMyFriends)\n",
    "library(igraph)\n",
    "\n",
    "setwd(\"/Users/matthewthompson/Documents/UAMS_SURF/K-mer_testing/FAA_files\")\n",
    "genomeFiles <- list.files(getwd(), full.names=TRUE, pattern='*.faa')\n",
    "pan <- pangenome(genomeFiles[1:27], translated=TRUE, geneLocation='prodigal', lowMem=FALSE)\n",
    "pan <- gpcGrouping(pan, lowerLimit=0.5)\n",
    "pan\n",
    "\n",
    "# pie chart and gene graph\n",
    "plotStat(pan, type='qual', palette=6)\n",
    "\n",
    "# see how pangenome composition changes as genomes are added\n",
    "plotEvolution(pan)\n",
    "\n",
    "# heatmap based on % of similar genes\n",
    "plotSimilarity(pan)\n",
    "\n",
    "# heatmap based on kmer similarity\n",
    "plotSimilarity(pan, type='kmer', kmerSize=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, RStudio crashed while running the gpcGrouping analysis for all 27 genomes. I decided to try to run it with a smaller set of genomes. It took around 19 minutes for the gpcGrouping to finish for the 10 genomes. Results:\n",
    "![summPlot](images/w2/10sumplot.png)\n",
    "![evoPlot](images/w2/10evoplot.png)\n",
    "Clustered based on % gene similarity\n",
    "![tree](images/w2/phylotree.png)\n",
    "Split by % genes shared:\n",
    "![pHM](images/w2/10percentHM.png)\n",
    "Split by kmer profiles:\n",
    "![kHM](images/w2/10kmerHM.png)\n",
    "\n",
    "To check and see if FMF is reproducible, I reran the analysis and got slightly different gene classification ratios. \n",
    "![summPlot](images/w2/Re10SummPlot.png)\n",
    "Clustered based on % gene similarity\n",
    "![tree](images/w2/ReTree.png)\n",
    "Split by % genes shared:\n",
    "![pHM](images/w2/RePHM.png)\n",
    "Split by kmer profiles:\n",
    "![kHM](images/w2/ReKmerHM.png)\n",
    "\n",
    "The heatmaps and tree still look the same, but I will have to continue investigating tomorrow. \n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wednesday May 29, 2019:\n",
    "* I decided to test the reproducibility of FindMyFriends by running it for 8 genomes 5 times to compare results. \n",
    "* while FMF was running, I read about various clustering algorithms to try to get some ideas for a preclustering stept\n",
    "\n",
    "FindMyFriends version 1.1.6 does not give reproducible results. Each time I ran the program, I got different core, accessory, and singleton counts for the pangenome. ![comparisonGraphs](images/w2/FMF1.1.6SummaryGraphs-1.png)\n",
    "\n",
    "I think this might arise from Thomas' Guided Pairwise Comparison method: \n",
    "\n",
    "\"FindMyFriends does away with [computational time and memory restrictions] by introducing a new approach called Guided Pairwise Comparison (GPC). It works by building a tree of the organisms in the set, and recursively combine pangenomes of subtrees into new pangenomes. **Each time two pangenomes are combined, representatives for each gene group in the two pangenomes are chosen at random and compared to each other using kmer similarity.** The resulting grouping is then propagated to genes in the two pangenomes. \" \n",
    "\n",
    "I was initially told that the random step came from the CD-Hit clustering, but this random representative picking is present in FindMyFriends even before CD-Hit. My next plan of attack is to test an earlier version before GPC was added to see if I can get reproducible results. \n",
    "\n",
    "While I was waiting for the graphs to be produced for version 1.1.5, I found the piece of code that randomly samples from the subtree groups to represent each subtree: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In FindMyFriends aaa.R, line 436 in method RecurseCompare()\n",
    "represent <- sapply(groups, function(x) {\n",
    "        x[sample.int(length(x), size = 1L)]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graphs for FMF1.1.5 were also not reproducible:\n",
    "![1.1.5](images/w2/FMF1.1.5graphs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily, there is a separate way to group genes in FindMyFriends by getting a kmer similarity matrix and then grouping the genes with a separate algorithm. I then tested that method three times and found that it did give reproducible results! Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(FindMyFriends)\n",
    "library(igraph)\n",
    "\n",
    "setwd(\"/Users/matthewthompson/Documents/UAMS_SURF/K-mer_testing/FAA_files\")\n",
    "genomeFiles <- list.files(getwd(), full.names=TRUE, pattern='*.faa')\n",
    "pan <- pangenome(genomeFiles[1:8], translated=TRUE, geneLocation='prodigal', lowMem=FALSE)\n",
    "panSim <- kmerSimilarity(pan, lowerLimit=0.8, rescale=FALSE)\n",
    "pan <- graphGrouping(pan, panSim)\n",
    "pan\n",
    "plotStat(pan, type='qual', palette=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Thursday May 30, 2019:\n",
    "* try to find a canopy clustering algorithm to test\n",
    "\n",
    "I found a good python version of canopy clustering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gdbasset canopy.py gist on github: https://gist.github.com/gdbassett/528d816d035f2deaaca1\n",
    "\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import numpy as np\n",
    "\n",
    "# X shoudl be a numpy matrix, very likely sparse matrix: http://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.sparse.csr_matrix.html#scipy.sparse.csr_matrix\n",
    "# T1 > T2 for overlapping clusters\n",
    "# T1 = Distance to centroid point to not include in other clusters\n",
    "# T2 = Distance to centroid point to include in cluster\n",
    "# T1 > T2 for overlapping clusters\n",
    "# T1 < T2 will have points which reside in no clusters\n",
    "# T1 == T2 will cause all points to reside in mutually exclusive clusters\n",
    "# Distance metric can be any from here: http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.pairwise_distances.html\n",
    "# filemap may be a list of point names in their order in X. If included, row numbers from X will be replaced with names from filemap. \n",
    " \n",
    "def canopy(X, T1, T2, distance_metric='euclidean', filemap=None):\n",
    "    canopies = dict()\n",
    "    X1_dist = pairwise_distances(X, metric=distance_metric)\n",
    "    print(X1_dist)\n",
    "    canopy_points = set(range(X.shape[0]))\n",
    "    while canopy_points:\n",
    "        point = canopy_points.pop()\n",
    "        i = len(canopies)\n",
    "        canopies[i] = {\"c\":point, \"points\": list(np.where(X1_dist[point] < T2)[0])}\n",
    "        canopy_points = canopy_points.difference(set(np.where(X1_dist[point] < T1)[0]))\n",
    "    if filemap:\n",
    "        for canopy_id in canopies.keys():\n",
    "            canopy = canopies.pop(canopy_id)\n",
    "            canopy2 = {\"c\":filemap[canopy['c']], \"points\":list()}\n",
    "            for point in canopy['points']:\n",
    "                canopy2[\"points\"].append(filemap[point])\n",
    "            canopies[canopy_id] = canopy2\n",
    "    return canopies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since FindMyFriends was in R, I decided to go ahead a try to write my own version of the canopy clustering algorithm in R. It was good practice learning to work with data structures in R. My version turned out to be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(FindMyFriends)\n",
    "library(kebabs)\n",
    "library(rlist)\n",
    "\n",
    "setwd(\"/Users/matthewthompson/Documents/UAMS_SURF/K-mer_testing/FAA_files\")\n",
    "genomeFiles <- list.files(getwd(), full.names=TRUE, pattern='*.faa')\n",
    "pan <- pangenome(genomeFiles[1:6], translated=TRUE, geneLocation='prodigal', lowMem=FALSE)\n",
    "distance_matrix <- kmerSimilarity(pan, kmerSize = 4, lowerLimit=0, rescale=TRUE)\n",
    "\n",
    "cleaned_names <- c()\n",
    "for(name in rownames(distance_matrix)){\n",
    "  print(name)\n",
    "  print(strsplit(name, \" \")[[1]][1])\n",
    "  cleaned_names <- c(cleaned_names, strsplit(name, \" \")[[1]][1])\n",
    "}\n",
    "rownames(distance_matrix) <- cleaned_names\n",
    "colnames(distance_matrix) <- cleaned_names\n",
    "\n",
    "points <- rownames(distance_matrix)\n",
    "canopies <- list()\n",
    "while(length(points) > 0){\n",
    "  center_point = tail(points, 1)\n",
    "  print(c(\"canopy center point: \", center_point))\n",
    "  points <- points[!(points == center_point)]\n",
    "  \n",
    "  T1 <- 0.8\n",
    "  T2 <- 0.2\n",
    "  canopy_points <- c()\n",
    "  for(entry in names(distance_matrix[center_point,])){\n",
    "    if(distance_matrix[center_point, entry] < T1){\n",
    "      canopy_points <- c(canopy_points, entry)\n",
    "    }\n",
    "    if(distance_matrix[center_point, entry] > 0){\n",
    "      print(distance_matrix[center_point, entry])\n",
    "    }\n",
    "    if(distance_matrix[center_point, entry] < T2){\n",
    "      points <- points[!(points == entry)]\n",
    "    }\n",
    "  }\n",
    "  print(c(\"points not in canopy at end\", length(points)))\n",
    "  canopies[[center_point]] <- canopy_points[]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I need to test it and make sure that it clusters the data well enough. The matrix seems way too sparse, so I will have to check it out in depth tomorrow.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Friday May 31, 2019:\n",
    "* continue testing canopy clustering\n",
    "* check distance matrix\n",
    "* group meeting\n",
    "* SURF/INBRE luncheon\n",
    "\n",
    "I tried to test my canopy clustering code, but it was too slow and did not perform as desired. The worst step is the distance matrix calculation, and this calculation actually defeats the purpose of the canopy clustering algorithm. I decided to do some further research and see what I could find on quick ways to cluster genomic data, and I came across a few metagenomic papers ([Clustering Metagenome Sequences Using Canopies](https://www.searchdl.org/Resources/Public/Conf/2017/BICOB/149793953041.pdf), [16S rRNA metagenome clustering and diversity estimation using locality sensitive hashing](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3854655/pdf/1752-0509-7-S4-S11.pdf) ) that use a method called local sensitivity hashing (LSH) to compare sequences based on their kmers. To get a better idea of the algorithm, I watched a series of [youtube videos](https://www.youtube.com/watch?v=dgH0NP8Qxa8) (LSH.8 and following on the same channel). With LSH, the time complexity is O(log(N)) where N is the input data size. LSH was used in the above Clustering Metagenome Sequences Using Canopies paper as the quick distance metric for canopy clustering, so it may be useful for FindMyFriends.\n",
    "\n",
    "Before pursuing LSH too far, Kaleb advised me to try to get the python canopy clustering algorithm working first, so I worked on that next. I used the following code to try to read in the .csv files, but spyder (the python IDE) ran out of memory while trying to calculate the distances for the points. I will have to try this on Kaleb's more powerful CPU, and maybe he can give me some tips on how to improve the program. I am still learning how to manage all of this data effectively, and it is a complex task! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified from gdbasset canopy.py gist on github: https://gist.github.com/gdbassett/528d816d035f2deaaca1\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "# X shoudl be a numpy matrix, very likely sparse matrix: http://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.sparse.csr_matrix.html#scipy.sparse.csr_matrix\n",
    "# T1 > T2 for overlapping clusters\n",
    "# T1 = Distance to centroid point to not include in other clusters\n",
    "# T2 = Distance to centroid point to include in cluster\n",
    "# T1 > T2 for overlapping clusters\n",
    "# T1 < T2 will have points which reside in no clusters\n",
    "# T1 == T2 will cause all points to reside in mutually exclusive clusters\n",
    "# Distance metric can be any from here: http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.pairwise_distances.html\n",
    "# filemap may be a list of point names in their order in X. If included, row numbers from X will be replaced with names from filemap. \n",
    " \n",
    "def canopy(X, T1, T2, distance_metric='euclidean', filemap=None):\n",
    "    canopies = dict()\n",
    "    X1_dist = pairwise_distances(X, metric=distance_metric)\n",
    "    canopy_points = set(range(X.shape[0]))\n",
    "    iteration = 0\n",
    "    while canopy_points:\n",
    "        iteration = iteration + 1\n",
    "        print(\"iteration: \" + iteration)\n",
    "        point = canopy_points.pop()\n",
    "        i = len(canopies)\n",
    "        canopies[i] = {\"c\":point, \"points\": list(np.where(X1_dist[point] < T2)[0])}\n",
    "        canopy_points = canopy_points.difference(set(np.where(X1_dist[point] < T1)[0]))\n",
    "    if filemap:\n",
    "        for canopy_id in canopies.keys():\n",
    "            canopy = canopies.pop(canopy_id)\n",
    "            canopy2 = {\"c\":filemap[canopy['c']], \"points\":list()}\n",
    "            for point in canopy['points']:\n",
    "                canopy2[\"points\"].append(filemap[point])\n",
    "            canopies[canopy_id] = canopy2\n",
    "    return canopies\n",
    "\n",
    "def main():\n",
    "    df = pd.read_csv('/Users/matthewthompson/Documents/UAMS_SURF/K-mer_testing/FAA_files/k4_kmer_top_10_table.csv')\n",
    "    #gets protein_ids\n",
    "    kmers = list(df['Unnamed: 0'])\n",
    "    df['kmers'] = kmers\n",
    "    #move from data column to index column\n",
    "    df.set_index('kmers',inplace = True)\n",
    "    #delete protein header list\n",
    "    del df['Unnamed: 0']\n",
    "    df = df.T\n",
    "    df.head(3)\n",
    "    print(\"canopy clustering:\")\n",
    "    print(canopy(df.to_numpy(), 0.7, 0.5))\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
